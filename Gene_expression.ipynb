{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Eye State Detection.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WRhCR9cy8T8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#conda install -c conda-forge pydotplus00\n",
        "#conda install -c gafortiby sklearn-pandas \n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Krri7AXy8UM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "random_seed = 123\n",
        "np.random.seed(random_seed)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7DJU4Tny8Ua",
        "colab_type": "text"
      },
      "source": [
        "# 1. Reading the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfVk15kDy8Uc",
        "colab_type": "text"
      },
      "source": [
        "Histone modifications play an important role in affecting gene regulation. Specific histone modifications at specific locations in or near the gene can alter the expression of genes. Predicting gene expression from histone modification signals is a widely studied research topic.\n",
        "\n",
        "In this competition you will predict gene expression levels (low=0, high=1) based on the presence of histone modifications at specific locations in the gene. You will try to find the model that learns the true underlying model best.\n",
        "\n",
        "For each gene a region of 10.000bp around the transcription start site of the gene is extracted (5000bp upstream and 5000bp downstream). This region is binned in 100 bins of 100bp. For each bin five core histone modification marks are counted [1].\n",
        "\n",
        "The dataset is compiled from the \"E047\" (Primary T CD8+ naive cells from peripheral blood) celltype from Roadmap Epigenomics Mapping Consortium (REMC) database.\n",
        "\n",
        "[1] Kundaje, A. et al. Integrative analysis of 111 reference human epige-\n",
        "nomes. Nature, 518, 317–330, 2015."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fEaghfDy8Ue",
        "colab_type": "text"
      },
      "source": [
        "We start by loading the Pandas library and reading the datasets into Pandas DataFrames:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alZpE70qy8Uh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/ML-course-VIB-2020/master/data_train.csv\")\n",
        "test = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/ML-course-VIB-2020/master/data_test.csv\")\n",
        "test_label = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/ML-course-VIB-2020/master/data_test_label.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WA6pU9qDy8U0",
        "colab_type": "text"
      },
      "source": [
        "Let's look at the first 5 rows of the trainset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBIQBcTTy8U1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "f1036a4c-4438-4b2f-aaed-9994021d0ee5"
      },
      "source": [
        "train.head(5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GeneId</th>\n",
              "      <th>H3K4me3_0</th>\n",
              "      <th>H3K4me1_0</th>\n",
              "      <th>H3K36me3_0</th>\n",
              "      <th>H3K9me3_0</th>\n",
              "      <th>H3K27me3_0</th>\n",
              "      <th>H3K4me3_1</th>\n",
              "      <th>H3K4me1_1</th>\n",
              "      <th>H3K36me3_1</th>\n",
              "      <th>H3K9me3_1</th>\n",
              "      <th>H3K27me3_1</th>\n",
              "      <th>H3K4me3_2</th>\n",
              "      <th>H3K4me1_2</th>\n",
              "      <th>H3K36me3_2</th>\n",
              "      <th>H3K9me3_2</th>\n",
              "      <th>H3K27me3_2</th>\n",
              "      <th>H3K4me3_3</th>\n",
              "      <th>H3K4me1_3</th>\n",
              "      <th>H3K36me3_3</th>\n",
              "      <th>H3K9me3_3</th>\n",
              "      <th>H3K27me3_3</th>\n",
              "      <th>H3K4me3_4</th>\n",
              "      <th>H3K4me1_4</th>\n",
              "      <th>H3K36me3_4</th>\n",
              "      <th>H3K9me3_4</th>\n",
              "      <th>H3K27me3_4</th>\n",
              "      <th>H3K4me3_5</th>\n",
              "      <th>H3K4me1_5</th>\n",
              "      <th>H3K36me3_5</th>\n",
              "      <th>H3K9me3_5</th>\n",
              "      <th>H3K27me3_5</th>\n",
              "      <th>H3K4me3_6</th>\n",
              "      <th>H3K4me1_6</th>\n",
              "      <th>H3K36me3_6</th>\n",
              "      <th>H3K9me3_6</th>\n",
              "      <th>H3K27me3_6</th>\n",
              "      <th>H3K4me3_7</th>\n",
              "      <th>H3K4me1_7</th>\n",
              "      <th>H3K36me3_7</th>\n",
              "      <th>H3K9me3_7</th>\n",
              "      <th>...</th>\n",
              "      <th>H3K4me1_92</th>\n",
              "      <th>H3K36me3_92</th>\n",
              "      <th>H3K9me3_92</th>\n",
              "      <th>H3K27me3_92</th>\n",
              "      <th>H3K4me3_93</th>\n",
              "      <th>H3K4me1_93</th>\n",
              "      <th>H3K36me3_93</th>\n",
              "      <th>H3K9me3_93</th>\n",
              "      <th>H3K27me3_93</th>\n",
              "      <th>H3K4me3_94</th>\n",
              "      <th>H3K4me1_94</th>\n",
              "      <th>H3K36me3_94</th>\n",
              "      <th>H3K9me3_94</th>\n",
              "      <th>H3K27me3_94</th>\n",
              "      <th>H3K4me3_95</th>\n",
              "      <th>H3K4me1_95</th>\n",
              "      <th>H3K36me3_95</th>\n",
              "      <th>H3K9me3_95</th>\n",
              "      <th>H3K27me3_95</th>\n",
              "      <th>H3K4me3_96</th>\n",
              "      <th>H3K4me1_96</th>\n",
              "      <th>H3K36me3_96</th>\n",
              "      <th>H3K9me3_96</th>\n",
              "      <th>H3K27me3_96</th>\n",
              "      <th>H3K4me3_97</th>\n",
              "      <th>H3K4me1_97</th>\n",
              "      <th>H3K36me3_97</th>\n",
              "      <th>H3K9me3_97</th>\n",
              "      <th>H3K27me3_97</th>\n",
              "      <th>H3K4me3_98</th>\n",
              "      <th>H3K4me1_98</th>\n",
              "      <th>H3K36me3_98</th>\n",
              "      <th>H3K9me3_98</th>\n",
              "      <th>H3K27me3_98</th>\n",
              "      <th>H3K4me3_99</th>\n",
              "      <th>H3K4me1_99</th>\n",
              "      <th>H3K36me3_99</th>\n",
              "      <th>H3K9me3_99</th>\n",
              "      <th>H3K27me3_99</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7008</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>14</td>\n",
              "      <td>30</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>21</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>31</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>31</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9839</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11972</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14705</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12058</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 502 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   GeneId  H3K4me3_0  H3K4me1_0  ...  H3K9me3_99  H3K27me3_99  Label\n",
              "0    7008          1          1  ...           2            2      1\n",
              "1    9839          0          0  ...           0            0      1\n",
              "2   11972          7          3  ...           1            0      0\n",
              "3   14705          4          2  ...           0            0      0\n",
              "4   12058          1          1  ...           1            0      1\n",
              "\n",
              "[5 rows x 502 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYHeBhf8y8VC",
        "colab_type": "text"
      },
      "source": [
        "There is a column called `GeneId` that identifies the gene. This column should not be used as a feature. \n",
        "\n",
        "The label for each datapoint is in the `Label` column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZuSUhLu4L8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ids = train.pop(\"GeneId\")\n",
        "train_labels = train.pop(\"Label\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DHXHPpo4SBG",
        "colab_type": "text"
      },
      "source": [
        "Now `train` contains the feature columns only.\n",
        "\n",
        "Let's look at the number datapoints in each class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynUhI2de6TsU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "2b46c1ee-d28f-415a-e57b-99fc9737dd8d"
      },
      "source": [
        "train_labels.value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    5250\n",
              "0    5186\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4eZlOyO6NNF",
        "colab_type": "text"
      },
      "source": [
        "Let's look at `test`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDV9hz5Ay8VD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "6fa67a72-4737-42fc-b1da-d8709ae889ea"
      },
      "source": [
        "test.head(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GeneId</th>\n",
              "      <th>H3K4me3_0</th>\n",
              "      <th>H3K4me1_0</th>\n",
              "      <th>H3K36me3_0</th>\n",
              "      <th>H3K9me3_0</th>\n",
              "      <th>H3K27me3_0</th>\n",
              "      <th>H3K4me3_1</th>\n",
              "      <th>H3K4me1_1</th>\n",
              "      <th>H3K36me3_1</th>\n",
              "      <th>H3K9me3_1</th>\n",
              "      <th>H3K27me3_1</th>\n",
              "      <th>H3K4me3_2</th>\n",
              "      <th>H3K4me1_2</th>\n",
              "      <th>H3K36me3_2</th>\n",
              "      <th>H3K9me3_2</th>\n",
              "      <th>H3K27me3_2</th>\n",
              "      <th>H3K4me3_3</th>\n",
              "      <th>H3K4me1_3</th>\n",
              "      <th>H3K36me3_3</th>\n",
              "      <th>H3K9me3_3</th>\n",
              "      <th>H3K27me3_3</th>\n",
              "      <th>H3K4me3_4</th>\n",
              "      <th>H3K4me1_4</th>\n",
              "      <th>H3K36me3_4</th>\n",
              "      <th>H3K9me3_4</th>\n",
              "      <th>H3K27me3_4</th>\n",
              "      <th>H3K4me3_5</th>\n",
              "      <th>H3K4me1_5</th>\n",
              "      <th>H3K36me3_5</th>\n",
              "      <th>H3K9me3_5</th>\n",
              "      <th>H3K27me3_5</th>\n",
              "      <th>H3K4me3_6</th>\n",
              "      <th>H3K4me1_6</th>\n",
              "      <th>H3K36me3_6</th>\n",
              "      <th>H3K9me3_6</th>\n",
              "      <th>H3K27me3_6</th>\n",
              "      <th>H3K4me3_7</th>\n",
              "      <th>H3K4me1_7</th>\n",
              "      <th>H3K36me3_7</th>\n",
              "      <th>H3K9me3_7</th>\n",
              "      <th>...</th>\n",
              "      <th>H3K4me3_92</th>\n",
              "      <th>H3K4me1_92</th>\n",
              "      <th>H3K36me3_92</th>\n",
              "      <th>H3K9me3_92</th>\n",
              "      <th>H3K27me3_92</th>\n",
              "      <th>H3K4me3_93</th>\n",
              "      <th>H3K4me1_93</th>\n",
              "      <th>H3K36me3_93</th>\n",
              "      <th>H3K9me3_93</th>\n",
              "      <th>H3K27me3_93</th>\n",
              "      <th>H3K4me3_94</th>\n",
              "      <th>H3K4me1_94</th>\n",
              "      <th>H3K36me3_94</th>\n",
              "      <th>H3K9me3_94</th>\n",
              "      <th>H3K27me3_94</th>\n",
              "      <th>H3K4me3_95</th>\n",
              "      <th>H3K4me1_95</th>\n",
              "      <th>H3K36me3_95</th>\n",
              "      <th>H3K9me3_95</th>\n",
              "      <th>H3K27me3_95</th>\n",
              "      <th>H3K4me3_96</th>\n",
              "      <th>H3K4me1_96</th>\n",
              "      <th>H3K36me3_96</th>\n",
              "      <th>H3K9me3_96</th>\n",
              "      <th>H3K27me3_96</th>\n",
              "      <th>H3K4me3_97</th>\n",
              "      <th>H3K4me1_97</th>\n",
              "      <th>H3K36me3_97</th>\n",
              "      <th>H3K9me3_97</th>\n",
              "      <th>H3K27me3_97</th>\n",
              "      <th>H3K4me3_98</th>\n",
              "      <th>H3K4me1_98</th>\n",
              "      <th>H3K36me3_98</th>\n",
              "      <th>H3K9me3_98</th>\n",
              "      <th>H3K27me3_98</th>\n",
              "      <th>H3K4me3_99</th>\n",
              "      <th>H3K4me1_99</th>\n",
              "      <th>H3K36me3_99</th>\n",
              "      <th>H3K9me3_99</th>\n",
              "      <th>H3K27me3_99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5222</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>891</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7219</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7225</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9432</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 501 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   GeneId  H3K4me3_0  H3K4me1_0  ...  H3K36me3_99  H3K9me3_99  H3K27me3_99\n",
              "0    5222          2          2  ...            1           1            1\n",
              "1     891          1          2  ...            5           2            1\n",
              "2    7219          1          1  ...            1           1            0\n",
              "3    7225          1          5  ...            0           2            0\n",
              "4    9432          1         16  ...            1           2            1\n",
              "\n",
              "[5 rows x 501 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mao3WMV3y8VJ",
        "colab_type": "text"
      },
      "source": [
        "This is a blind test so the `eyeDetection` column is not available in the testset. The testset does contain a column called `index` that you will need to send your predictions to the Kaggle website.\n",
        "\n",
        "Let's look at the shape of the train- and testset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4VjbA3ey8VN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "88be2935-1b39-46ec-c527-267c17f9c696"
      },
      "source": [
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10436, 500)\n",
            "(5049, 501)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbiH1uzSy8VT",
        "colab_type": "text"
      },
      "source": [
        "We can get some general statistics about the trainset using the DataFrame `.describe()` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPg1lbiWy8VV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "82e5d5f8-10a3-4273-9558-d5be27ba2d80"
      },
      "source": [
        "train.describe().transpose()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>H3K4me3_0</th>\n",
              "      <td>10436.0</td>\n",
              "      <td>1.482081</td>\n",
              "      <td>1.883112</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H3K4me1_0</th>\n",
              "      <td>10436.0</td>\n",
              "      <td>1.738885</td>\n",
              "      <td>2.098565</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H3K36me3_0</th>\n",
              "      <td>10436.0</td>\n",
              "      <td>2.342564</td>\n",
              "      <td>3.798700</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>45.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H3K9me3_0</th>\n",
              "      <td>10436.0</td>\n",
              "      <td>1.887792</td>\n",
              "      <td>5.292531</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>104.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H3K27me3_0</th>\n",
              "      <td>10436.0</td>\n",
              "      <td>1.134438</td>\n",
              "      <td>1.455765</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>41.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H3K4me3_99</th>\n",
              "      <td>10436.0</td>\n",
              "      <td>1.455922</td>\n",
              "      <td>1.842602</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H3K4me1_99</th>\n",
              "      <td>10436.0</td>\n",
              "      <td>1.738022</td>\n",
              "      <td>2.134836</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H3K36me3_99</th>\n",
              "      <td>10436.0</td>\n",
              "      <td>2.397183</td>\n",
              "      <td>3.892699</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H3K9me3_99</th>\n",
              "      <td>10436.0</td>\n",
              "      <td>1.826945</td>\n",
              "      <td>4.924786</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>115.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H3K27me3_99</th>\n",
              "      <td>10436.0</td>\n",
              "      <td>1.129935</td>\n",
              "      <td>1.472372</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>43.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               count      mean       std  min  25%  50%  75%    max\n",
              "H3K4me3_0    10436.0  1.482081  1.883112  0.0  0.0  1.0  2.0   21.0\n",
              "H3K4me1_0    10436.0  1.738885  2.098565  0.0  0.0  1.0  2.0   24.0\n",
              "H3K36me3_0   10436.0  2.342564  3.798700  0.0  0.0  1.0  3.0   45.0\n",
              "H3K9me3_0    10436.0  1.887792  5.292531  0.0  0.0  1.0  2.0  104.0\n",
              "H3K27me3_0   10436.0  1.134438  1.455765  0.0  0.0  1.0  2.0   41.0\n",
              "...              ...       ...       ...  ...  ...  ...  ...    ...\n",
              "H3K4me3_99   10436.0  1.455922  1.842602  0.0  0.0  1.0  2.0   27.0\n",
              "H3K4me1_99   10436.0  1.738022  2.134836  0.0  0.0  1.0  2.0   35.0\n",
              "H3K36me3_99  10436.0  2.397183  3.892699  0.0  0.0  1.0  3.0   35.0\n",
              "H3K9me3_99   10436.0  1.826945  4.924786  0.0  0.0  1.0  2.0  115.0\n",
              "H3K27me3_99  10436.0  1.129935  1.472372  0.0  0.0  1.0  2.0   43.0\n",
              "\n",
              "[500 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kDGcmkU2KE5",
        "colab_type": "text"
      },
      "source": [
        "# 2. Data pre-processing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oltcoOqH3TTD",
        "colab_type": "text"
      },
      "source": [
        "We can use the Pandas `boxplot()` function to plot the feature values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjZd6rZs3ijb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "2416d040-e2a8-4474-eabd-1c44abec088a"
      },
      "source": [
        "plt.figure(figsize=(22,8))\n",
        "train.boxplot()\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-8b3d1fd6f0aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \"\"\"\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(*objs, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2101\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n\u001b[0;32m-> 2103\u001b[0;31m                             bbox_extra_artists=bbox_artists)\n\u001b[0m\u001b[1;32m   2104\u001b[0m                     \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pad_inches\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mpad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   2393\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m                     bbox = ax.get_tightbbox(renderer,\n\u001b[0;32m-> 2395\u001b[0;31m                             bbox_extra_artists=bbox_extra_artists)\n\u001b[0m\u001b[1;32m   2396\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m                     \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, call_axes_locator, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   4321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxison\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4323\u001b[0;31m             \u001b[0mbb_xaxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4324\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbb_xaxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4325\u001b[0m                 \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb_xaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;31m# go back to just this axis's tick labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(\n\u001b[0;32m-> 1192\u001b[0;31m                     ticks_to_draw, renderer)\n\u001b[0m\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_offset_text_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticklabelBoxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticklabelBoxes2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_bboxes\u001b[0;34m(self, ticks, renderer)\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0;32m-> 1174\u001b[0;31m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0m\u001b[1;32m   1175\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[1;32m   1176\u001b[0m                  for tick in ticks if tick.label2.get_visible()])\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0;32m-> 1174\u001b[0;31m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0m\u001b[1;32m   1175\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[1;32m   1176\u001b[0m                  for tick in ticks if tick.label2.get_visible()])\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get window extent w/o renderer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36m_get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    291\u001b[0m         _, lp_h, lp_d = renderer.get_text_width_height_descent(\n\u001b[1;32m    292\u001b[0m             \u001b[0;34m\"lp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fontproperties\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             ismath=\"TeX\" if self.get_usetex() else False)\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mmin_dy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlp_h\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlp_d\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linespacing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[0;34m(self, s, prop, ismath)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mflags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hinting_flag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_agg_font\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_width_height\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# width and height of unrotated string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv7vShayzrR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "marks = {}\n",
        "for m in train.columns:\n",
        "  marks[m.split(\"_\")[0]] = True\n",
        "marks = list(marks.keys())\n",
        "marks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIwcZXHX0lO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for mark in marks:\n",
        "  cols = []\n",
        "  for m in train.columns:\n",
        "    if mark in m:\n",
        "      cols.append(m)\n",
        "  plt.figure(figsize=(22,8))    \n",
        "  train[cols].boxplot()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNCXrS1x4Tf8",
        "colab_type": "text"
      },
      "source": [
        "In this case I choose scaling the features to [0,1]:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGkTWm904gt9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "0023c8ad-01e4-4b8c-c262-d9fdde190de8"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "scaler_minmax = preprocessing.MinMaxScaler()\n",
        "scaler_minmax.fit(train)\n",
        "train_norm = pd.DataFrame(scaler_minmax.transform(train),columns=train.columns)\n",
        "train_norm.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>H3K4me3_0</th>\n",
              "      <th>H3K4me1_0</th>\n",
              "      <th>H3K36me3_0</th>\n",
              "      <th>H3K9me3_0</th>\n",
              "      <th>H3K27me3_0</th>\n",
              "      <th>H3K4me3_1</th>\n",
              "      <th>H3K4me1_1</th>\n",
              "      <th>H3K36me3_1</th>\n",
              "      <th>H3K9me3_1</th>\n",
              "      <th>H3K27me3_1</th>\n",
              "      <th>H3K4me3_2</th>\n",
              "      <th>H3K4me1_2</th>\n",
              "      <th>H3K36me3_2</th>\n",
              "      <th>H3K9me3_2</th>\n",
              "      <th>H3K27me3_2</th>\n",
              "      <th>H3K4me3_3</th>\n",
              "      <th>H3K4me1_3</th>\n",
              "      <th>H3K36me3_3</th>\n",
              "      <th>H3K9me3_3</th>\n",
              "      <th>H3K27me3_3</th>\n",
              "      <th>H3K4me3_4</th>\n",
              "      <th>H3K4me1_4</th>\n",
              "      <th>H3K36me3_4</th>\n",
              "      <th>H3K9me3_4</th>\n",
              "      <th>H3K27me3_4</th>\n",
              "      <th>H3K4me3_5</th>\n",
              "      <th>H3K4me1_5</th>\n",
              "      <th>H3K36me3_5</th>\n",
              "      <th>H3K9me3_5</th>\n",
              "      <th>H3K27me3_5</th>\n",
              "      <th>H3K4me3_6</th>\n",
              "      <th>H3K4me1_6</th>\n",
              "      <th>H3K36me3_6</th>\n",
              "      <th>H3K9me3_6</th>\n",
              "      <th>H3K27me3_6</th>\n",
              "      <th>H3K4me3_7</th>\n",
              "      <th>H3K4me1_7</th>\n",
              "      <th>H3K36me3_7</th>\n",
              "      <th>H3K9me3_7</th>\n",
              "      <th>H3K27me3_7</th>\n",
              "      <th>...</th>\n",
              "      <th>H3K4me3_92</th>\n",
              "      <th>H3K4me1_92</th>\n",
              "      <th>H3K36me3_92</th>\n",
              "      <th>H3K9me3_92</th>\n",
              "      <th>H3K27me3_92</th>\n",
              "      <th>H3K4me3_93</th>\n",
              "      <th>H3K4me1_93</th>\n",
              "      <th>H3K36me3_93</th>\n",
              "      <th>H3K9me3_93</th>\n",
              "      <th>H3K27me3_93</th>\n",
              "      <th>H3K4me3_94</th>\n",
              "      <th>H3K4me1_94</th>\n",
              "      <th>H3K36me3_94</th>\n",
              "      <th>H3K9me3_94</th>\n",
              "      <th>H3K27me3_94</th>\n",
              "      <th>H3K4me3_95</th>\n",
              "      <th>H3K4me1_95</th>\n",
              "      <th>H3K36me3_95</th>\n",
              "      <th>H3K9me3_95</th>\n",
              "      <th>H3K27me3_95</th>\n",
              "      <th>H3K4me3_96</th>\n",
              "      <th>H3K4me1_96</th>\n",
              "      <th>H3K36me3_96</th>\n",
              "      <th>H3K9me3_96</th>\n",
              "      <th>H3K27me3_96</th>\n",
              "      <th>H3K4me3_97</th>\n",
              "      <th>H3K4me1_97</th>\n",
              "      <th>H3K36me3_97</th>\n",
              "      <th>H3K9me3_97</th>\n",
              "      <th>H3K27me3_97</th>\n",
              "      <th>H3K4me3_98</th>\n",
              "      <th>H3K4me1_98</th>\n",
              "      <th>H3K36me3_98</th>\n",
              "      <th>H3K9me3_98</th>\n",
              "      <th>H3K27me3_98</th>\n",
              "      <th>H3K4me3_99</th>\n",
              "      <th>H3K4me1_99</th>\n",
              "      <th>H3K36me3_99</th>\n",
              "      <th>H3K9me3_99</th>\n",
              "      <th>H3K27me3_99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.044444</td>\n",
              "      <td>0.009615</td>\n",
              "      <td>0.073171</td>\n",
              "      <td>0.023810</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.119048</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.195122</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.074074</td>\n",
              "      <td>0.186047</td>\n",
              "      <td>0.017094</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.074074</td>\n",
              "      <td>0.024194</td>\n",
              "      <td>0.068966</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.009091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.155556</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.009091</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.552632</td>\n",
              "      <td>0.060606</td>\n",
              "      <td>0.038462</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.574074</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.704545</td>\n",
              "      <td>0.081818</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.566667</td>\n",
              "      <td>0.547619</td>\n",
              "      <td>0.027523</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.326531</td>\n",
              "      <td>0.058252</td>\n",
              "      <td>0.103448</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.394737</td>\n",
              "      <td>0.050505</td>\n",
              "      <td>0.068966</td>\n",
              "      <td>0.074074</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.342857</td>\n",
              "      <td>0.017391</td>\n",
              "      <td>0.046512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.022222</td>\n",
              "      <td>0.009615</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023256</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018519</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.022222</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.227273</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>0.037037</td>\n",
              "      <td>0.019608</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.022727</td>\n",
              "      <td>0.036364</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018349</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.020408</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.037037</td>\n",
              "      <td>0.028571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.022222</td>\n",
              "      <td>0.009615</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.023810</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.097561</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.037037</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008065</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.023810</td>\n",
              "      <td>0.018182</td>\n",
              "      <td>0.037037</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.044444</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.018182</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009091</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009174</td>\n",
              "      <td>0.107143</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020408</td>\n",
              "      <td>0.009709</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020202</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.037037</td>\n",
              "      <td>0.028571</td>\n",
              "      <td>0.028571</td>\n",
              "      <td>0.008696</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.088889</td>\n",
              "      <td>0.009615</td>\n",
              "      <td>0.073171</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.023810</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.037037</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008547</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.018519</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.023810</td>\n",
              "      <td>0.009091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.022222</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.009091</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.227273</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020408</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.078947</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.038462</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.227273</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.009091</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009174</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.020408</td>\n",
              "      <td>0.019417</td>\n",
              "      <td>0.068966</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.040404</td>\n",
              "      <td>0.068966</td>\n",
              "      <td>0.148148</td>\n",
              "      <td>0.085714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.044444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.195122</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.023810</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016667</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008547</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008065</td>\n",
              "      <td>0.275862</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.027273</td>\n",
              "      <td>0.185185</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.044444</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.078947</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>0.018519</td>\n",
              "      <td>0.009804</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.018182</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.023810</td>\n",
              "      <td>0.009174</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.020202</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.028571</td>\n",
              "      <td>0.028571</td>\n",
              "      <td>0.008696</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 500 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   H3K4me3_0  H3K4me1_0  H3K36me3_0  ...  H3K36me3_99  H3K9me3_99  H3K27me3_99\n",
              "0   0.047619   0.041667    0.044444  ...     0.342857    0.017391     0.046512\n",
              "1   0.000000   0.000000    0.022222  ...     0.000000    0.000000     0.000000\n",
              "2   0.333333   0.125000    0.022222  ...     0.028571    0.008696     0.000000\n",
              "3   0.190476   0.083333    0.088889  ...     0.000000    0.000000     0.000000\n",
              "4   0.047619   0.041667    0.044444  ...     0.028571    0.008696     0.000000\n",
              "\n",
              "[5 rows x 500 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYY3fLMq5RfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for mark in marks:\n",
        "  cols = []\n",
        "  for m in train_norm.columns:\n",
        "    if mark in m:\n",
        "      cols.append(m)\n",
        "  plt.figure(figsize=(22,8))    \n",
        "  train_norm[cols].boxplot()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FesoIiyNy8Vd",
        "colab_type": "text"
      },
      "source": [
        "# 3. Building a decision tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaqTeiPjy8Vg",
        "colab_type": "text"
      },
      "source": [
        "The scikit-learn `DecisionTreeClassifier` class computes a decision tree predictive model from a dataset. \n",
        "\n",
        "To get all the options for learning you can simply type: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGi4kfLzy8Vh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0e63187b-39c4-4265-a600-53c031c8fae0"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "help(DecisionTreeClassifier)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on class DecisionTreeClassifier in module sklearn.tree._classes:\n",
            "\n",
            "class DecisionTreeClassifier(sklearn.base.ClassifierMixin, BaseDecisionTree)\n",
            " |  A decision tree classifier.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <tree>`.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  criterion : {\"gini\", \"entropy\"}, default=\"gini\"\n",
            " |      The function to measure the quality of a split. Supported criteria are\n",
            " |      \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
            " |  \n",
            " |  splitter : {\"best\", \"random\"}, default=\"best\"\n",
            " |      The strategy used to choose the split at each node. Supported\n",
            " |      strategies are \"best\" to choose the best split and \"random\" to choose\n",
            " |      the best random split.\n",
            " |  \n",
            " |  max_depth : int, default=None\n",
            " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
            " |      all leaves are pure or until all leaves contain less than\n",
            " |      min_samples_split samples.\n",
            " |  \n",
            " |  min_samples_split : int or float, default=2\n",
            " |      The minimum number of samples required to split an internal node:\n",
            " |  \n",
            " |      - If int, then consider `min_samples_split` as the minimum number.\n",
            " |      - If float, then `min_samples_split` is a fraction and\n",
            " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
            " |        number of samples for each split.\n",
            " |  \n",
            " |      .. versionchanged:: 0.18\n",
            " |         Added float values for fractions.\n",
            " |  \n",
            " |  min_samples_leaf : int or float, default=1\n",
            " |      The minimum number of samples required to be at a leaf node.\n",
            " |      A split point at any depth will only be considered if it leaves at\n",
            " |      least ``min_samples_leaf`` training samples in each of the left and\n",
            " |      right branches.  This may have the effect of smoothing the model,\n",
            " |      especially in regression.\n",
            " |  \n",
            " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
            " |      - If float, then `min_samples_leaf` is a fraction and\n",
            " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
            " |        number of samples for each node.\n",
            " |  \n",
            " |      .. versionchanged:: 0.18\n",
            " |         Added float values for fractions.\n",
            " |  \n",
            " |  min_weight_fraction_leaf : float, default=0.0\n",
            " |      The minimum weighted fraction of the sum total of weights (of all\n",
            " |      the input samples) required to be at a leaf node. Samples have\n",
            " |      equal weight when sample_weight is not provided.\n",
            " |  \n",
            " |  max_features : int, float or {\"auto\", \"sqrt\", \"log2\"}, default=None\n",
            " |      The number of features to consider when looking for the best split:\n",
            " |  \n",
            " |          - If int, then consider `max_features` features at each split.\n",
            " |          - If float, then `max_features` is a fraction and\n",
            " |            `int(max_features * n_features)` features are considered at each\n",
            " |            split.\n",
            " |          - If \"auto\", then `max_features=sqrt(n_features)`.\n",
            " |          - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
            " |          - If \"log2\", then `max_features=log2(n_features)`.\n",
            " |          - If None, then `max_features=n_features`.\n",
            " |  \n",
            " |      Note: the search for a split does not stop until at least one\n",
            " |      valid partition of the node samples is found, even if it requires to\n",
            " |      effectively inspect more than ``max_features`` features.\n",
            " |  \n",
            " |  random_state : int or RandomState, default=None\n",
            " |      If int, random_state is the seed used by the random number generator;\n",
            " |      If RandomState instance, random_state is the random number generator;\n",
            " |      If None, the random number generator is the RandomState instance used\n",
            " |      by `np.random`.\n",
            " |  \n",
            " |  max_leaf_nodes : int, default=None\n",
            " |      Grow a tree with ``max_leaf_nodes`` in best-first fashion.\n",
            " |      Best nodes are defined as relative reduction in impurity.\n",
            " |      If None then unlimited number of leaf nodes.\n",
            " |  \n",
            " |  min_impurity_decrease : float, default=0.0\n",
            " |      A node will be split if this split induces a decrease of the impurity\n",
            " |      greater than or equal to this value.\n",
            " |  \n",
            " |      The weighted impurity decrease equation is the following::\n",
            " |  \n",
            " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
            " |                              - N_t_L / N_t * left_impurity)\n",
            " |  \n",
            " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
            " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
            " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
            " |  \n",
            " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
            " |      if ``sample_weight`` is passed.\n",
            " |  \n",
            " |      .. versionadded:: 0.19\n",
            " |  \n",
            " |  min_impurity_split : float, default=1e-7\n",
            " |      Threshold for early stopping in tree growth. A node will split\n",
            " |      if its impurity is above the threshold, otherwise it is a leaf.\n",
            " |  \n",
            " |      .. deprecated:: 0.19\n",
            " |         ``min_impurity_split`` has been deprecated in favor of\n",
            " |         ``min_impurity_decrease`` in 0.19. The default value of\n",
            " |         ``min_impurity_split`` will change from 1e-7 to 0 in 0.23 and it\n",
            " |         will be removed in 0.25. Use ``min_impurity_decrease`` instead.\n",
            " |  \n",
            " |  class_weight : dict, list of dict or \"balanced\", default=None\n",
            " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
            " |      If None, all classes are supposed to have weight one. For\n",
            " |      multi-output problems, a list of dicts can be provided in the same\n",
            " |      order as the columns of y.\n",
            " |  \n",
            " |      Note that for multioutput (including multilabel) weights should be\n",
            " |      defined for each class of every column in its own dict. For example,\n",
            " |      for four-class multilabel classification weights should be\n",
            " |      [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
            " |      [{1:1}, {2:5}, {3:1}, {4:1}].\n",
            " |  \n",
            " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
            " |      weights inversely proportional to class frequencies in the input data\n",
            " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
            " |  \n",
            " |      For multi-output, the weights of each column of y will be multiplied.\n",
            " |  \n",
            " |      Note that these weights will be multiplied with sample_weight (passed\n",
            " |      through the fit method) if sample_weight is specified.\n",
            " |  \n",
            " |  presort : deprecated, default='deprecated'\n",
            " |      This parameter is deprecated and will be removed in v0.24.\n",
            " |  \n",
            " |      .. deprecated:: 0.22\n",
            " |  \n",
            " |  ccp_alpha : non-negative float, default=0.0\n",
            " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
            " |      subtree with the largest cost complexity that is smaller than\n",
            " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
            " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
            " |  \n",
            " |      .. versionadded:: 0.22\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  classes_ : ndarray of shape (n_classes,) or list of ndarray\n",
            " |      The classes labels (single output problem),\n",
            " |      or a list of arrays of class labels (multi-output problem).\n",
            " |  \n",
            " |  feature_importances_ : ndarray of shape (n_features,)\n",
            " |      The feature importances. The higher, the more important the\n",
            " |      feature. The importance of a feature is computed as the (normalized)\n",
            " |      total reduction of the criterion brought by that feature.  It is also\n",
            " |      known as the Gini importance [4]_.\n",
            " |  \n",
            " |  max_features_ : int\n",
            " |      The inferred value of max_features.\n",
            " |  \n",
            " |  n_classes_ : int or list of int\n",
            " |      The number of classes (for single output problems),\n",
            " |      or a list containing the number of classes for each\n",
            " |      output (for multi-output problems).\n",
            " |  \n",
            " |  n_features_ : int\n",
            " |      The number of features when ``fit`` is performed.\n",
            " |  \n",
            " |  n_outputs_ : int\n",
            " |      The number of outputs when ``fit`` is performed.\n",
            " |  \n",
            " |  tree_ : Tree\n",
            " |      The underlying Tree object. Please refer to\n",
            " |      ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n",
            " |      :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\n",
            " |      for basic usage of these attributes.\n",
            " |  \n",
            " |  See Also\n",
            " |  --------\n",
            " |  DecisionTreeRegressor : A decision tree regressor.\n",
            " |  \n",
            " |  Notes\n",
            " |  -----\n",
            " |  The default values for the parameters controlling the size of the trees\n",
            " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
            " |  unpruned trees which can potentially be very large on some data sets. To\n",
            " |  reduce memory consumption, the complexity and size of the trees should be\n",
            " |  controlled by setting those parameter values.\n",
            " |  \n",
            " |  The features are always randomly permuted at each split. Therefore,\n",
            " |  the best found split may vary, even with the same training data and\n",
            " |  ``max_features=n_features``, if the improvement of the criterion is\n",
            " |  identical for several splits enumerated during the search of the best\n",
            " |  split. To obtain a deterministic behaviour during fitting,\n",
            " |  ``random_state`` has to be fixed.\n",
            " |  \n",
            " |  References\n",
            " |  ----------\n",
            " |  \n",
            " |  .. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n",
            " |  \n",
            " |  .. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification\n",
            " |         and Regression Trees\", Wadsworth, Belmont, CA, 1984.\n",
            " |  \n",
            " |  .. [3] T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical\n",
            " |         Learning\", Springer, 2009.\n",
            " |  \n",
            " |  .. [4] L. Breiman, and A. Cutler, \"Random Forests\",\n",
            " |         https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> from sklearn.datasets import load_iris\n",
            " |  >>> from sklearn.model_selection import cross_val_score\n",
            " |  >>> from sklearn.tree import DecisionTreeClassifier\n",
            " |  >>> clf = DecisionTreeClassifier(random_state=0)\n",
            " |  >>> iris = load_iris()\n",
            " |  >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
            " |  ...                             # doctest: +SKIP\n",
            " |  ...\n",
            " |  array([ 1.     ,  0.93...,  0.86...,  0.93...,  0.93...,\n",
            " |          0.93...,  0.93...,  1.     ,  0.93...,  1.      ])\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      DecisionTreeClassifier\n",
            " |      sklearn.base.ClassifierMixin\n",
            " |      BaseDecisionTree\n",
            " |      sklearn.base.MultiOutputMixin\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort='deprecated', ccp_alpha=0.0)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  fit(self, X, y, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
            " |      Build a decision tree classifier from the training set (X, y).\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The training input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csc_matrix``.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          The target values (class labels) as integers or strings.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights. If None, then samples are equally weighted. Splits\n",
            " |          that would create child nodes with net zero or negative weight are\n",
            " |          ignored while searching for a split in each node. Splits are also\n",
            " |          ignored if they would result in any single class carrying a\n",
            " |          negative weight in either child node.\n",
            " |      \n",
            " |      check_input : bool, default=True\n",
            " |          Allow to bypass several input checking.\n",
            " |          Don't use this parameter unless you know what you do.\n",
            " |      \n",
            " |      X_idx_sorted : array-like of shape (n_samples, n_features),                 default=None\n",
            " |          The indexes of the sorted training input samples. If many tree\n",
            " |          are grown on the same dataset, this allows the ordering to be\n",
            " |          cached between trees. If None, the data will be sorted here.\n",
            " |          Don't use this parameter unless you know what to do.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : DecisionTreeClassifier\n",
            " |          Fitted estimator.\n",
            " |  \n",
            " |  predict_log_proba(self, X)\n",
            " |      Predict class log-probabilities of the input samples X.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      proba : ndarray of shape (n_samples, n_classes) or list of n_outputs             such arrays if n_outputs > 1\n",
            " |          The class log-probabilities of the input samples. The order of the\n",
            " |          classes corresponds to that in the attribute :term:`classes_`.\n",
            " |  \n",
            " |  predict_proba(self, X, check_input=True)\n",
            " |      Predict class probabilities of the input samples X.\n",
            " |      \n",
            " |      The predicted class probability is the fraction of samples of the same\n",
            " |      class in a leaf.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      check_input : bool, default=True\n",
            " |          Allow to bypass several input checking.\n",
            " |          Don't use this parameter unless you know what you do.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      proba : ndarray of shape (n_samples, n_classes) or list of n_outputs             such arrays if n_outputs > 1\n",
            " |          The class probabilities of the input samples. The order of the\n",
            " |          classes corresponds to that in the attribute :term:`classes_`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
            " |  \n",
            " |  score(self, X, y, sample_weight=None)\n",
            " |      Return the mean accuracy on the given test data and labels.\n",
            " |      \n",
            " |      In multi-label classification, this is the subset accuracy\n",
            " |      which is a harsh metric since you require for each sample that\n",
            " |      each label set be correctly predicted.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Test samples.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          True labels for X.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : float\n",
            " |          Mean accuracy of self.predict(X) wrt. y.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from BaseDecisionTree:\n",
            " |  \n",
            " |  apply(self, X, check_input=True)\n",
            " |      Return the index of the leaf that each sample is predicted as.\n",
            " |      \n",
            " |      .. versionadded:: 0.17\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      check_input : bool, default=True\n",
            " |          Allow to bypass several input checking.\n",
            " |          Don't use this parameter unless you know what you do.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_leaves : array-like of shape (n_samples,)\n",
            " |          For each datapoint x in X, return the index of the leaf x\n",
            " |          ends up in. Leaves are numbered within\n",
            " |          ``[0; self.tree_.node_count)``, possibly with gaps in the\n",
            " |          numbering.\n",
            " |  \n",
            " |  cost_complexity_pruning_path(self, X, y, sample_weight=None)\n",
            " |      Compute the pruning path during Minimal Cost-Complexity Pruning.\n",
            " |      \n",
            " |      See :ref:`minimal_cost_complexity_pruning` for details on the pruning\n",
            " |      process.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The training input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csc_matrix``.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          The target values (class labels) as integers or strings.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights. If None, then samples are equally weighted. Splits\n",
            " |          that would create child nodes with net zero or negative weight are\n",
            " |          ignored while searching for a split in each node. Splits are also\n",
            " |          ignored if they would result in any single class carrying a\n",
            " |          negative weight in either child node.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      ccp_path : Bunch\n",
            " |          Dictionary-like object, with attributes:\n",
            " |      \n",
            " |          ccp_alphas : ndarray\n",
            " |              Effective alphas of subtree during pruning.\n",
            " |      \n",
            " |          impurities : ndarray\n",
            " |              Sum of the impurities of the subtree leaves for the\n",
            " |              corresponding alpha value in ``ccp_alphas``.\n",
            " |  \n",
            " |  decision_path(self, X, check_input=True)\n",
            " |      Return the decision path in the tree.\n",
            " |      \n",
            " |      .. versionadded:: 0.18\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      check_input : bool, default=True\n",
            " |          Allow to bypass several input checking.\n",
            " |          Don't use this parameter unless you know what you do.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      indicator : sparse matrix of shape (n_samples, n_nodes)\n",
            " |          Return a node indicator CSR matrix where non zero elements\n",
            " |          indicates that the samples goes through the nodes.\n",
            " |  \n",
            " |  get_depth(self)\n",
            " |      Return the depth of the decision tree.\n",
            " |      \n",
            " |      The depth of a tree is the maximum distance between the root\n",
            " |      and any leaf.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self.tree_.max_depth : int\n",
            " |          The maximum depth of the tree.\n",
            " |  \n",
            " |  get_n_leaves(self)\n",
            " |      Return the number of leaves of the decision tree.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self.tree_.n_leaves : int\n",
            " |          Number of leaves.\n",
            " |  \n",
            " |  predict(self, X, check_input=True)\n",
            " |      Predict class or regression value for X.\n",
            " |      \n",
            " |      For a classification model, the predicted class for each sample in X is\n",
            " |      returned. For a regression model, the predicted value based on X is\n",
            " |      returned.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      check_input : bool, default=True\n",
            " |          Allow to bypass several input checking.\n",
            " |          Don't use this parameter unless you know what you do.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          The predicted classes, or the predict values.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from BaseDecisionTree:\n",
            " |  \n",
            " |  feature_importances_\n",
            " |      Return the feature importances.\n",
            " |      \n",
            " |      The importance of a feature is computed as the (normalized) total\n",
            " |      reduction of the criterion brought by that feature.\n",
            " |      It is also known as the Gini importance.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      feature_importances_ : ndarray of shape (n_features,)\n",
            " |          Normalized total reduction of criteria by feature\n",
            " |          (Gini importance).\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : mapping of string to any\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as pipelines). The latter have parameters of the form\n",
            " |      ``<component>__<parameter>`` so that it's possible to update each\n",
            " |      component of a nested object.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          Estimator instance.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNn63QiNy8Vo",
        "colab_type": "text"
      },
      "source": [
        "You notice that there are many (hyper)parameters to set. These influence the complexity of the model. An important such parameter is the `max_depth` that set a limit on how deep a decision tree can become. \n",
        "\n",
        "Let's create a decision tree model with `max_depth=3`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0Pjoa08y8Vp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cls_DT = DecisionTreeClassifier(max_depth=3)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-0bRK0ky8Vy",
        "colab_type": "text"
      },
      "source": [
        "This creates a decision tree model with default values for the other hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vVO8Qnuy8V0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cls_DT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYVjJV6Ay8WF",
        "colab_type": "text"
      },
      "source": [
        "Now we can fit the trainset in just one line of code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPl3orbDy8WH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "fcd13049-9c0e-4be5-9fbe-11a7855ae592"
      },
      "source": [
        "cls_DT.fit(train_norm,train_labels)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBEx3Mv-y8WQ",
        "colab_type": "text"
      },
      "source": [
        "Let's see how well the decision tree performs on the trainset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR5qelPYy8WR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "dedcc35f-54bd-4bc4-94e7-f536e585d00a"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "predictions = cls_DT.predict(train_norm)\n",
        "print(\"Accuracy: %f\"%(accuracy_score(predictions, train_labels)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.825125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_Dq8upQy8WX",
        "colab_type": "text"
      },
      "source": [
        "These are the predictions for the first 100 data points:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRqE5_yHy8WX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions[0:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTaVvaUWI4_R",
        "colab_type": "text"
      },
      "source": [
        "For the Kaggle competition your predictions are not evaluated by accuracy, but by log-loss:\n",
        "\n",
        "$$ - \\frac{1}{N} \\sum_{i=1}^N [y_{i} \\log \\, p_{i} + (1 - y_{i}) \\log \\, (1 - p_{i})],$$\n",
        "\n",
        "where $N$ is the number of datapoints, $y_i$ is the label of datapoint $i$, and $p_i$ is the prediction of the model expressed as a probability.\n",
        "\n",
        "Let's compute the log-loss:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42cx7I0RetRk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0b4b5254-bc85-48d9-daf0-fef3693d2ba1"
      },
      "source": [
        "from sklearn.metrics import log_loss\n",
        "\n",
        "print(\"Log-loss: %f\"%log_loss(train_labels,predictions))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log-loss: 6.040057\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW3UFe1te5sZ",
        "colab_type": "text"
      },
      "source": [
        "This is a very high log-loss (note that we want the log-loss the be as close to zero as possible).\n",
        "\n",
        "The reason is that we don't actually provide probabilities but just the classes 0 and 1. Any error will be punished with a very high contribution to the log-loss. Therefor, we should predict class probabilities rather than just classes. \n",
        "\n",
        "Decision trees allow us to do that:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8oluzNCJQq6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ea7f05fd-ccf0-4a29-ce85-0387f5ffa414"
      },
      "source": [
        "from sklearn.metrics import log_loss\n",
        "\n",
        "predictions = cls_DT.predict_proba(train_norm)\n",
        "\n",
        "print(\"Log-loss: %f\"%log_loss(train_labels,predictions))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log-loss: 0.452246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LixpdZ7UfuH6",
        "colab_type": "text"
      },
      "source": [
        "Now the log-loss is much smaller."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZcpHy1My8Wj",
        "colab_type": "text"
      },
      "source": [
        "The following code plots the fitted decision tree `cls` as a `tree.png` file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H7Nlqs9y8Wl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "from sklearn import tree\n",
        "from io import StringIO\n",
        "from IPython.display import Image, display\n",
        "import pydotplus\n",
        "\n",
        "out = StringIO()\n",
        "tree.export_graphviz(cls_DT, out_file=out)\n",
        "graph=pydotplus.graph_from_dot_data(out.getvalue())\n",
        "graph.write_png(\"tree.png\")\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iSXs1tay8Wq",
        "colab_type": "text"
      },
      "source": [
        "# 4. Kaggle evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mclUVPCAy8Ws",
        "colab_type": "text"
      },
      "source": [
        "Let's make a Kaggle submission:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS-kgBKAy8Wt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#code for submission\n",
        "index_col = test.pop(\"GeneId\")\n",
        "predictions_test = cls_DT.predict_proba(test)\n",
        "\n",
        "out_tmp = pd.DataFrame()\n",
        "out_tmp[\"GeneId\"] = index_col\n",
        "out_tmp[\"eyeDetection\"] = predictions_test[:,1]\n",
        "out_tmp.to_csv(\"submission_DT.csv\",index=False)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl8OTjbZKvMp",
        "colab_type": "text"
      },
      "source": [
        "How does the model perform on the testset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9DhKikmy8W2",
        "colab_type": "text"
      },
      "source": [
        "# 5. Hyperparamters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ_O4Ezmy8W3",
        "colab_type": "text"
      },
      "source": [
        "For our first submission we set the hyperparameter `max_depth=3`. Other values might result in lower log-loss on the testset. \n",
        "\n",
        "Since we don't have the testset labels we can only check this on the public leaderboard, which we should not do!\n",
        "\n",
        "So, we need to create our own testset (**not seen during training!**) with known class labels.\n",
        "\n",
        "Scikit-learn offers many options to do this. One of them is the `train_test_split` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-U7t7hZy8W7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "6a7d939f-e88a-4638-cda4-a004b940ed31"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_X, val_X, train_y, val_y = train_test_split(train_norm,train_labels,\n",
        "                                                  test_size=.2, random_state=random_seed)\n",
        "\n",
        "#train fold\n",
        "print(train_X.shape)\n",
        "print(train_y.shape)\n",
        "#validation fold\n",
        "print(val_X.shape)\n",
        "print(val_y.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8348, 500)\n",
            "(8348,)\n",
            "(2088, 500)\n",
            "(2088,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEv2x3Smy8XB",
        "colab_type": "text"
      },
      "source": [
        "Fit a decision tree model with default paramters on the `train_X` data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx29OyFly8XD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "81a7e07f-6ba6-4268-cc8f-aeae7fbf5acb"
      },
      "source": [
        "#solution\n",
        "cls_DT = DecisionTreeClassifier(max_depth=14)\n",
        "cls_DT.fit(train_X,train_y)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=14, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH9q5De8y8XI",
        "colab_type": "text"
      },
      "source": [
        "What is the accuracy on `train_X`? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW3HjC5Dy8XJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "99f6947a-ddee-4ef8-ecd5-28ccb12affc7"
      },
      "source": [
        "#solution\n",
        "predictions = cls_DT.predict(train_X)\n",
        "print(\"Accuracy: %f\"%(accuracy_score(predictions, train_y)))\n",
        "predictions = cls_DT.predict_proba(train_X)\n",
        "print(\"Log-loss: %f\"%(log_loss(train_y,predictions[:,1])))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.954001\n",
            "Log-loss: 0.155349\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqHXtasSy8XO",
        "colab_type": "text"
      },
      "source": [
        "What is the accuracy on `val_X`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm7GVlo-y8XQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ca198e67-2538-463b-9847-8a0bb725e7e1"
      },
      "source": [
        "#solution\n",
        "predictions = cls_DT.predict(val_X)\n",
        "print(\"Accuracy: %f\"%(accuracy_score(predictions, val_y)))\n",
        "predictions = cls_DT.predict_proba(val_X)\n",
        "print(\"Log-loss: %f\"%(log_loss(val_y,predictions[:,1])))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.805556\n",
            "Log-loss: 4.407348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1p535f2y8XY",
        "colab_type": "text"
      },
      "source": [
        "What do you see?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBRBR7Q4y8Xd",
        "colab_type": "text"
      },
      "source": [
        "The following code evaluates different values for this hyperparameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6avhhiiy8Xe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "dd41f025-d6a3-4720-e5bc-0c74be7c318f"
      },
      "source": [
        "for maxdepth in range(1,20,1):\n",
        "    cls = DecisionTreeClassifier(max_depth=maxdepth)\n",
        "    cls.fit(train_X,train_y)\n",
        "    predictions_train = cls.predict(train_X)\n",
        "    predictions_val = cls.predict(val_X)\n",
        "    predictions_train_prob = cls.predict_proba(train_X)[:,1]\n",
        "    predictions_val_prob = cls.predict_proba(val_X)[:,1]\n",
        "    print(\"%i (%f) %f (%f) %f\"%(maxdepth,\n",
        "                                accuracy_score(predictions_train, train_y),accuracy_score(predictions_val, val_y),\n",
        "                                log_loss(train_y,predictions_train_prob),log_loss(val_y,predictions_val_prob)))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 (0.787254) 0.795019 (0.517571) 0.507348\n",
            "2 (0.810134) 0.811782 (0.484475) 0.479824\n",
            "3 (0.822353) 0.818008 (0.456446) 0.461147\n",
            "4 (0.825587) 0.818487 (0.427133) 0.456196\n",
            "5 (0.840920) 0.820402 (0.401390) 0.590077\n",
            "6 (0.851102) 0.826628 (0.378458) 0.761725\n",
            "7 (0.864878) 0.827586 (0.355997) 0.850584\n",
            "8 (0.878773) 0.828544 (0.327821) 1.028743\n",
            "9 (0.894705) 0.817529 (0.291779) 1.647373\n",
            "10 (0.910278) 0.812739 (0.260448) 2.016281\n",
            "11 (0.925491) 0.817529 (0.225833) 2.566585\n",
            "12 (0.939027) 0.811782 (0.193870) 3.449689\n",
            "13 (0.947532) 0.810345 (0.171298) 3.849344\n",
            "14 (0.954121) 0.802203 (0.152804) 4.598492\n",
            "15 (0.961548) 0.806992 (0.135780) 4.777776\n",
            "16 (0.963464) 0.808908 (0.128609) 4.734535\n",
            "17 (0.966459) 0.805556 (0.117869) 5.178614\n",
            "18 (0.970292) 0.805077 (0.106601) 5.326464\n",
            "19 (0.971730) 0.801724 (0.100003) 5.535981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOxT7dLan5Nr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "6881a892-52de-4433-81a4-c01971118446"
      },
      "source": [
        "for run in range(5):\n",
        "  train_X, val_X, train_y, val_y = train_test_split(train_norm,train_labels,\n",
        "                                                  test_size=.8, random_state=run)\n",
        "  min_m = 100\n",
        "  best = None\n",
        "  for maxdepth in range(1,20,1):\n",
        "      cls = DecisionTreeClassifier(max_depth=maxdepth)\n",
        "      cls.fit(train_X,train_y)\n",
        "      predictions_val_prob = cls.predict_proba(val_X)[:,1]\n",
        "      m = log_loss(val_y,predictions_val_prob)\n",
        "      if m < min_m:\n",
        "        min_m = m\n",
        "        best = maxdepth\n",
        "  print(\"%i %f\"%(best,min_m))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 0.489871\n",
            "2 0.501669\n",
            "3 0.479379\n",
            "2 0.491435\n",
            "3 0.479280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhFFLaJ_sG9L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "f19faf0e-5d72-4baf-ed95-adb3c5b2526b"
      },
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "for maxdepth in range(1,20,1):\n",
        "    cls = DecisionTreeClassifier(max_depth=maxdepth)\n",
        "    predictions = cross_val_predict(cls,train_norm,train_labels,\n",
        "                                    cv=10,\n",
        "                                    method=\"predict_proba\")\n",
        "    print(\"%i %f\"%(maxdepth,log_loss(train_labels,predictions[:,1])))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 0.518693\n",
            "2 0.488489\n",
            "3 0.469868\n",
            "4 0.458350\n",
            "5 0.509028\n",
            "6 0.623721\n",
            "7 0.856069\n",
            "8 1.143359\n",
            "9 1.498481\n",
            "10 2.002092\n",
            "11 2.603200\n",
            "12 3.051423\n",
            "13 3.532863\n",
            "14 4.041015\n",
            "15 4.432267\n",
            "16 4.737619\n",
            "17 4.963082\n",
            "18 5.359835\n",
            "19 5.440707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgVOx2SLsIGV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "2c2bb9fa-63a1-4c1a-af9f-07a318ccf645"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {\n",
        "    'max_depth':range(1,20)\n",
        "    }\n",
        "\n",
        "GSCV = GridSearchCV(cls_DT, params,\n",
        "                    cv=10,\n",
        "                    scoring=\"neg_log_loss\",\n",
        "                    verbose=1).fit(train_norm,train_labels)\n",
        "\n",
        "print(GSCV.best_estimator_)\n",
        "print(GSCV.best_score_)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 19 candidates, totalling 190 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-1a54c6cf18aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"neg_log_loss\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                     verbose=1).fit(train_norm,train_labels)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGSCV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUgY_6Ply8X3",
        "colab_type": "text"
      },
      "source": [
        "Play with the hyperparameters in a Template notebook and make some Kaggle submissions.\n",
        "\n",
        "# 5. Ensemble learning: bagging\n",
        "\n",
        "We have seen that bias and variance play an important role in Machine Learning. Let's first see what bagging can do for our data set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m16JfepBy8X4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "cls_bagged = BaggingClassifier(base_estimator=DecisionTreeClassifier(),random_state=random_seed)\n",
        "                                                            \n",
        "cls_bagged.fit(train_X,train_y)\n",
        "predictions_train = cls_bagged.predict(train_X)\n",
        "predictions_val = cls_bagged.predict(val_X)\n",
        "print(\"%f %f\"%(accuracy_score(predictions_train, train_y),accuracy_score(predictions_val, val_y)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsA-43z8y8X9",
        "colab_type": "text"
      },
      "source": [
        "With the `RandomForestClassifier` the variance of the decision tree is reduced also by selecting features for decision tree contruction at random. Let's see how far we get with default hyperparameter values.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIfSnbtGy8X-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "aeb72168-1cd4-4ae7-8335-a0b367a11ad2"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "cls_RF = RandomForestClassifier(random_state=random_seed)\n",
        "cls_RF.fit(train_X,train_y)\n",
        "predictions_train = cls_RF.predict(train_X)\n",
        "predictions_val = cls_RF.predict(val_X)\n",
        "print(\"%f %f\"%(accuracy_score(predictions_train, train_y),accuracy_score(predictions_val, val_y)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.999521 0.864464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExwDeHLNy8YH",
        "colab_type": "text"
      },
      "source": [
        "Now let's see what we can do with the `RandomForestClassifier`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozJTH3m3y8YJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "help(RandomForestClassifier)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q74zK-Ghy8YQ",
        "colab_type": "text"
      },
      "source": [
        "What happens when you increase the `n_estimators` hyperparameter? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npmmU8W_y8YR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#solution"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nn-e3Gujy8Ya",
        "colab_type": "text"
      },
      "source": [
        "# 6. Ensemble learning: boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI1CdRroy8Yc",
        "colab_type": "text"
      },
      "source": [
        "How about the `GradientBoostingClassifier`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hR1KZv_y8Yd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#solution\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "cls_GB = GradientBoostingClassifier(random_state=random_seed,max_depth=10)\n",
        "cls_GB.fit(train_norm,train_filtered_label)\n",
        "predictions_train = cls_GB.predict(train_norm)\n",
        "predictions_val = cls_GB.predict(test_norm)\n",
        "print(\"%f %f\"%(accuracy_score(predictions_train, train_filtered_label),accuracy_score(predictions_val, test_label)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cis3fW5gy8Yh",
        "colab_type": "text"
      },
      "source": [
        "# 7. Logistic regression\n",
        "\n",
        "Before we evaluate other Machine Learning algorithms such as logistic regression we need to look at the distributions and scales of the features. In fact, this should always be the first thing to do when analyzing a new data set.\n",
        "\n",
        "In Pandas we can create a boxplot for each of the features as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZHbB47Ny8Yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X.boxplot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wkpl_Zq6y8Yq",
        "colab_type": "text"
      },
      "source": [
        "What do we see?\n",
        "\n",
        "There are many approaches to outlier detection and removal. Let's use a simple one:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iL8gA-Yy8Yq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import stats\n",
        "\n",
        "print(X.shape)\n",
        "tmp = (np.abs(stats.zscore(X)) < 3).all(axis=1)\n",
        "X_clean = X[tmp]\n",
        "y_clean = y[tmp]\n",
        "print(X_clean.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjRtzA8Zy8Yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_clean.boxplot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0Pc6XCay8Yy",
        "colab_type": "text"
      },
      "source": [
        "This should look much better.\n",
        "\n",
        "However, feature values between features are still at very different scales. We need to normalize them. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYKKKkWzy8ZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit(X_clean)\n",
        "X_norm = pd.DataFrame(scaler.transform(X_clean),columns=X_clean.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezh6auGoy8ZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_norm.boxplot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfCRI_dWy8ZT",
        "colab_type": "text"
      },
      "source": [
        "Now each feature is at a similar scale.\n",
        "\n",
        "Let's start with `LogisticRegression`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnypOpCwy8ZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "train_X, val_X, train_y, val_y = train_test_split(X_norm,y_clean,test_size=.2, random_state=random_seed)\n",
        "\n",
        "cls_LR=LogisticRegression()\n",
        "cls_LR.fit(train_X,train_y)\n",
        "predictions_train = cls_LR.predict(train_X)\n",
        "predictions_val = cls_LR.predict(val_X)\n",
        "print(\"%f %f\"%(accuracy_score(predictions_train, train_y),accuracy_score(predictions_val, val_y)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEKNx2Diy8ZY",
        "colab_type": "text"
      },
      "source": [
        "Does this perform well?\n",
        "\n",
        "What could be the reason?\n",
        "\n",
        "# 8. Non-linear transformations\n",
        "\n",
        "What does linear classification mean?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LVmHyQ0y8ZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "dataset_tmp = pd.read_csv('svm_example1.csv')\n",
        "\n",
        "sns.lmplot(x=\"x1\", y=\"x2\", data=dataset_tmp, hue='y', markers=['o','+'], \n",
        "           fit_reg=False, height=5, scatter_kws={\"s\": 80})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHsp1Mxry8Zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imp\n",
        "compomics_import = imp.load_source('compomics_import', 'compomics_import.py')\n",
        "\n",
        "X_tmp = dataset_tmp.copy()\n",
        "y_tmp = X_tmp.pop('y')\n",
        "\n",
        "cls_LR.fit(X_tmp,y_tmp)\n",
        "\n",
        "sns.lmplot(x=\"x1\", y=\"x2\", data=dataset_tmp, hue='y', markers=['o','+'], \n",
        "           fit_reg=False, height=5, scatter_kws={\"s\": 80})\n",
        "compomics_import.plot_svm_decision_function(cls_LR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca0YBhYpy8Zf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "polynomial_features = PolynomialFeatures(degree=2)\n",
        "model = Pipeline([(\"polynomial_features\", polynomial_features),\n",
        "                         (\"LR\", cls_LR)])\n",
        "model.fit(X_tmp,y_tmp)\n",
        "\n",
        "sns.lmplot(x=\"x1\", y=\"x2\", data=dataset_tmp, hue='y', markers=['o','+'], \n",
        "           fit_reg=False, height=5, scatter_kws={\"s\": 80})\n",
        "compomics_import.plot_svm_decision_function(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h9Xx7mVy8Zh",
        "colab_type": "text"
      },
      "source": [
        "What happens when you increase the degree?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2ve0_mCy8Zi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#solution"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY-yZX8Jy8Zk",
        "colab_type": "text"
      },
      "source": [
        "Would this work on our dataset?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QEpAqrMy8Zn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#solution "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qkRuouFy8Zp",
        "colab_type": "text"
      },
      "source": [
        "Kaggle submission?\n",
        "\n",
        "The following code ranks the features based on the value of the hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29lzLPiBy8Zr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indices = np.argsort(cls_LR.coef_[0])[::-1]\n",
        "fnames = poly.get_feature_names()\n",
        "for i in range(len(fnames)):\n",
        "    print(\"%f\\t%s\"%(cls_LR.coef_[0][indices[i]],fnames[indices[i]]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMwZxS--y8Zv",
        "colab_type": "text"
      },
      "source": [
        "What is wrong with this code?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP8_RLKQy8Zw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#solution"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGz-v3thy8Zy",
        "colab_type": "text"
      },
      "source": [
        "# 9. Support Vector Machines\n",
        "\n",
        "Let's see what an SVM can do with an RBF kernel:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrHPX_ULy8Zz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SVC(kernel='poly',C=1,degree=2)\n",
        "model.fit(X_tmp,y_tmp)\n",
        "\n",
        "sns.lmplot(x=\"x1\", y=\"x2\", data=dataset_tmp, hue='y', markers=['o','+'], \n",
        "           fit_reg=False, height=5, scatter_kws={\"s\": 80})\n",
        "compomics_import.plot_svm_decision_function(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDpj_rTcy8Z3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset2_tmp = pd.read_csv(\"svm_example2.csv\")\n",
        "X_tmp = dataset2_tmp.copy()\n",
        "y_tmp = X_tmp.pop('y')\n",
        "\n",
        "model = SVC(kernel='rbf',C=1,gamma=1)\n",
        "model.fit(X_tmp,y_tmp)\n",
        "\n",
        "sns.lmplot(x=\"x1\", y=\"x2\", data=dataset2_tmp, hue='y', markers=['o','+'], \n",
        "           fit_reg=False, height=5, scatter_kws={\"s\": 80})\n",
        "compomics_import.plot_svm_decision_function(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AdHtrT2y8Z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X, val_X, train_y, val_y = train_test_split(X_norm,y_clean,test_size=.2, random_state=random_seed)\n",
        "\n",
        "cls_SVM = SVC(kernel='rbf')\n",
        "cls_SVM.fit(train_X,train_y)\n",
        "predictions_train = cls_SVM.predict(train_X)\n",
        "predictions_val = cls_SVM.predict(val_X)\n",
        "print(\"%f %f\"%(accuracy_score(predictions_train, train_y),accuracy_score(predictions_val, val_y)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys3jDeS_y8Z9",
        "colab_type": "text"
      },
      "source": [
        "# 10. Neural Networks\n",
        "\n",
        "How about a Neural Network?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C98inA3Uy8Z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "cls_MLP=MLPClassifier(hidden_layer_sizes=(60,10))\n",
        "cls_MLP.fit(train_X,train_y)\n",
        "predictions_train = cls_MLP.predict(train_X)\n",
        "predictions_val = cls_MLP.predict(val_X)\n",
        "print(\"%f %f\"%(accuracy_score(predictions_train, train_y),accuracy_score(predictions_val, val_y)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1jCml-Ay8aC",
        "colab_type": "text"
      },
      "source": [
        "Is feature normalization required?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkkxBGX1y8aD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X, val_X, train_y, val_y = train_test_split(X,y,test_size=.2, random_state=random_seed)\n",
        "cls_MLP.fit(train_X,train_y)\n",
        "predictions_train = cls_MLP.predict(train_X)\n",
        "predictions_val = cls_MLP.predict(val_X)\n",
        "print(\"%f %f\"%(accuracy_score(predictions_train, train_y),accuracy_score(predictions_val, val_y)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY2q-A-my8aF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}